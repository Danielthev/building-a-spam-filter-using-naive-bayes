{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter Using Naive Bayes\n",
    "### Introduction\n",
    "\n",
    "There are several classification techniques in the area of machine learning. One such technique is the Naive Bayes algorithm. The Naive Bayes is a family of classifiers, and through the use of probabilities, determines the class of an object. In this project, I endeavour to create a spam filter using the multinomial Naive Bayes algorithm. The dataset I will be using has 5572 SMS messages, and it was constructed by Tiago A. Almeida and Jose Maria Gomez Hidalgo. The dataset can be downloaded from the <a href=\"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\" target=\"_blank\">The UCI Machine learning Repository</a>. These messages have already been classified as spam or ham (not spam).\n",
    "\n",
    "The goal of this project is to create an algorithm that can classify SMS messages by training it with as many already classfied messages as possible. In so doing, the algorithm will become a more effective classifier, and thus, the accuracy of our spam filter will be higher.\n",
    "\n",
    "I begin by reading in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas library and read in the data\n",
    "#The dataset does not have a header row. So, I create one.\n",
    "\n",
    "import pandas\n",
    "\n",
    "smsdata = pandas.read_csv(r'C:\\Users\\Daniel\\.jupyter\\SMSSpamCollection', sep = '\\t', header = None, names = ['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data\n",
    "\n",
    "Below, I explore the data a little bit, and as can be seen, there are 5572 rows and 2 columns. You'll also find the first five rows of the dataset. Moreover, this dataset is comprised of ~87% ham messages and ~13% spam messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the number of rows and columns of the dataset\n",
    "#Explore the first few rows of the dataset\n",
    "\n",
    "print(smsdata.shape)\n",
    "smsdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the proportion of spam and ham messages\n",
    "\n",
    "smsdata['Label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Test Sets\n",
    "\n",
    "In this next step, I split the original dataset to create a training set and test set. I, first, randomize the original dataset, and then assign 85% of the observations to the training set and the remaining 15% to the test set. The purpose of splitting the dataset is simply to leverage the fact that all the messages have already been classified. By performing this step, I will be able to compare the predicted labels to the actual labels, and thus, determine the accuracy of the spam filter. \n",
    "\n",
    "The 85/15 split is partly arbitrary, but the idea is to train the algorithm with as many messages as possible so as to have just enough observations on which to test the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4736, 2)\n",
      "(836, 2)\n"
     ]
    }
   ],
   "source": [
    "#Randomize the dataset\n",
    "#Split the dataset into a training set (w/ 85% of the data) and a test set (w/ 15% of the data)\n",
    "\n",
    "rand_set = smsdata.sample(frac = 1, random_state = 1)\n",
    "rand_set_index = round(len(rand_set) * 0.85)\n",
    "train_set = rand_set[:rand_set_index].reset_index(drop = True)\n",
    "test_set = rand_set[rand_set_index:].reset_index(drop = True)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see that both the training and test sets closely resemble the composition of the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865921\n",
       "spam    0.134079\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the proportion of ham and spam messages for the training set\n",
    "\n",
    "train_set['Label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866029\n",
       "spam    0.133971\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the proportion of ham and spam messages for the test set\n",
    "\n",
    "test_set['Label'].value_counts(normalize = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "The next few steps will involve cleaning the training set so that it can be used by our Naive Bayes algorithm. To understand why the next steps are necessary, it's important to understand the construction of the Naive Bayes algorithm. \n",
    "\n",
    "The Naive Bayes algorithm is based on Bayes' Theorem. The algorithm is 'naive' because it assumes conditional independence between elements within an object (i.e. words within a message). Hence, the formula looks like the following:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?P(Spam|w_1,w_2,...,w_n)&space;\\propto&space;P(Spam)&space;\\cdot&space;{\\displaystyle&space;\\prod_{i=1}^{n}&space;P(w_i|Spam)}\" title=\"P(Spam|w_1,w_2,...,w_n) \\propto P(Spam) \\cdot {\\displaystyle \\prod_{i=1}^{n} P(w_i|Spam)}\" />\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?P(Ham|w_1,w_2,...,w_n)&space;\\propto&space;P(Ham)&space;\\cdot&space;{\\displaystyle&space;\\prod_{i=1}^{n}&space;P(w_i|Ham)}\" title=\"P(Ham|w_1,w_2,...,w_n) \\propto P(Ham) \\cdot {\\displaystyle \\prod_{i=1}^{n} P(w_i|Ham)}\" />\n",
    "\n",
    "Where $\\propto$ means directly proportional to and $w_i$ represents a word in the message. Notice there isn't a denominator for the above equations. This is done to optimize the algorithm. Ridding the equations of the denominators won't affect the algorithm's ability to classify new messages. Hence, the directly proportional symbol, $\\propto$. \n",
    "\n",
    "So, in the following steps, the goal is to create a complete dataframe that includes columns for the unique words in the training set. The values for these columns will be the number of times a respective word appears in a certain message. Below is the training set before the data cleaning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set before data cleaning\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step of the data cleaning process, I remove punctuations from all the messages in the training set and convert the messages to lowercase. I, then, create a vocabulary list, which is comprised of all the unique words in the training set. As seen below, there are 8,030 unique words in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove from the messages any punctuations\n",
    "#Convert the messages to lowercase\n",
    "#Training set after data cleaning\n",
    "\n",
    "train_set['SMS'] = train_set['SMS'].str.replace('\\W', ' ')\n",
    "train_set['SMS'] = train_set['SMS'].str.lower()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a vocabulary list, which is a set of unique words that make up the messages in the training set\n",
    "\n",
    "train_set['SMS'] = train_set['SMS'].str.split() #The split function is to convert the string into a list of the elements\n",
    "\n",
    "vocab = []\n",
    "\n",
    "for sms in train_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocab.append(word)\n",
    "\n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8030"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the number of words in the vocabulary\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having created the vocabulary list, I construct a dataframe that has the unique words of the training set comprise its columns. I, then, combine this dataframe with the training set dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tissco</th>\n",
       "      <th>n8</th>\n",
       "      <th>trained</th>\n",
       "      <th>someday</th>\n",
       "      <th>sec</th>\n",
       "      <th>dontcha</th>\n",
       "      <th>dnt</th>\n",
       "      <th>embarassing</th>\n",
       "      <th>rumbling</th>\n",
       "      <th>grow</th>\n",
       "      <th>...</th>\n",
       "      <th>mumhas</th>\n",
       "      <th>imagination</th>\n",
       "      <th>wildlife</th>\n",
       "      <th>embarassed</th>\n",
       "      <th>hypotheticalhuagauahahuagahyuhagga</th>\n",
       "      <th>deck</th>\n",
       "      <th>shitin</th>\n",
       "      <th>523</th>\n",
       "      <th>abuse</th>\n",
       "      <th>monos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8030 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tissco  n8  trained  someday  sec  dontcha  dnt  embarassing  rumbling  \\\n",
       "0       0   0        0        0    0        0    0            0         0   \n",
       "1       0   0        0        0    0        0    0            0         0   \n",
       "2       0   0        0        0    0        0    0            0         0   \n",
       "3       0   0        0        0    0        0    0            0         0   \n",
       "4       0   0        0        0    0        0    0            0         0   \n",
       "\n",
       "   grow  ...  mumhas  imagination  wildlife  embarassed  \\\n",
       "0     0  ...       0            0         0           0   \n",
       "1     0  ...       0            0         0           0   \n",
       "2     0  ...       0            0         0           0   \n",
       "3     0  ...       0            0         0           0   \n",
       "4     0  ...       0            0         0           0   \n",
       "\n",
       "   hypotheticalhuagauahahuagahyuhagga  deck  shitin  523  abuse  monos  \n",
       "0                                   0     0       0    0      0      0  \n",
       "1                                   0     0       0    0      0      0  \n",
       "2                                   0     0       0    0      0      0  \n",
       "3                                   0     0       0    0      0      0  \n",
       "4                                   0     0       0    0      0      0  \n",
       "\n",
       "[5 rows x 8030 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe that has the unique words in the training set as its columns\n",
    "#The values in the columns represent the number of the times a respective word appears in a certain message \n",
    "\n",
    "#Initialize a dictionary of unique words that have values of 0\n",
    "word_counts_per_sms = {unique_word: [0] * len(train_set['SMS']) for unique_word in vocab} \n",
    "\n",
    "#Use enumerate function to assign an index to each sms in the training set\n",
    "for index, sms in enumerate(train_set['SMS']): \n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "word_counts = pandas.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>tissco</th>\n",
       "      <th>n8</th>\n",
       "      <th>trained</th>\n",
       "      <th>someday</th>\n",
       "      <th>sec</th>\n",
       "      <th>dontcha</th>\n",
       "      <th>dnt</th>\n",
       "      <th>embarassing</th>\n",
       "      <th>...</th>\n",
       "      <th>mumhas</th>\n",
       "      <th>imagination</th>\n",
       "      <th>wildlife</th>\n",
       "      <th>embarassed</th>\n",
       "      <th>hypotheticalhuagauahahuagahyuhagga</th>\n",
       "      <th>deck</th>\n",
       "      <th>shitin</th>\n",
       "      <th>523</th>\n",
       "      <th>abuse</th>\n",
       "      <th>monos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8032 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  tissco  n8  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]       0   0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...       0   0   \n",
       "2   ham                    [welp, apparently, he, retired]       0   0   \n",
       "3   ham                                           [havent]       0   0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...       0   0   \n",
       "\n",
       "   trained  someday  sec  dontcha  dnt  embarassing  ...  mumhas  imagination  \\\n",
       "0        0        0    0        0    0            0  ...       0            0   \n",
       "1        0        0    0        0    0            0  ...       0            0   \n",
       "2        0        0    0        0    0            0  ...       0            0   \n",
       "3        0        0    0        0    0            0  ...       0            0   \n",
       "4        0        0    0        0    0            0  ...       0            0   \n",
       "\n",
       "   wildlife  embarassed  hypotheticalhuagauahahuagahyuhagga  deck  shitin  \\\n",
       "0         0           0                                   0     0       0   \n",
       "1         0           0                                   0     0       0   \n",
       "2         0           0                                   0     0       0   \n",
       "3         0           0                                   0     0       0   \n",
       "4         0           0                                   0     0       0   \n",
       "\n",
       "   523  abuse  monos  \n",
       "0    0      0      0  \n",
       "1    0      0      0  \n",
       "2    0      0      0  \n",
       "3    0      0      0  \n",
       "4    0      0      0  \n",
       "\n",
       "[5 rows x 8032 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the training set and word counts dataframes\n",
    "\n",
    "train_set_clean = pandas.concat([train_set, word_counts], axis = 1)\n",
    "train_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Spam Filter\n",
    "\n",
    "Now that I've cleaned the data, I can begin creating the variables needed to construct the Naive Bayes algorithm. These variables include the probabilities of spam and ham messages, and the parameters (or probabilities of unique words given spam or ham messages). Notice that I defined a variable named alpha and stored a value of 1 in it. This is to help us calculate the parameters of the Naive Bayes algorithm, and it will be further explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store spam and ham messages separate variables\n",
    "\n",
    "spam_sms = train_set_clean[train_set_clean['Label'] == 'spam']\n",
    "ham_sms = train_set_clean[train_set_clean['Label'] == 'ham']\n",
    "\n",
    "#Store the total number of words in spam messages and ham messages in separate variables \n",
    "\n",
    "n_spam = spam_sms['SMS'].apply(len).sum()\n",
    "n_ham = ham_sms['SMS'].apply(len).sum()\n",
    "\n",
    "#Store number of words in vocabulary in a variable\n",
    "#Define a variable called alpha and store in it a value of 1 \n",
    "\n",
    "n_vocab = len(vocab)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the probability of spam and ham messages in separate variables\n",
    "\n",
    "p_spam = len(spam_sms) / len(train_set_clean)\n",
    "p_ham = len(ham_sms) / len(train_set_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the calculation of the parameters in our training set. A parameter represents the probability value of a particular word given spam ($ P(w_i|Spam) $) or ham ($ P(w_i|Ham) $). \n",
    "\n",
    "I calculate the parameters the following way:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?P(w_i|Spam)&space;=&space;\\dfrac{N_{w_i|Spam}&space;&plus;&space;\\alpha}{N_{Spam}&space;&plus;&space;\\alpha&space;\\cdot&space;N_{Vocabulary}}\" title=\"P(w_i|Spam) = \\dfrac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\" />\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?P(w_i|Ham)&space;=&space;\\dfrac{N_{w_i|Ham}&space;&plus;&space;\\alpha}{N_{Ham}&space;&plus;&space;\\alpha&space;\\cdot&space;N_{Vocabulary}}\" title=\"P(w_i|Ham) = \\dfrac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\" />\n",
    "\n",
    "Where $N_{w_i|Spam}$ is the number of a particular word in all spam messages, $N_{w_i|Ham}$ is the number of a particular word in all ham messages, $N_{Spam}$ is the number of words in all spam messages, and $N_{Ham}$ is the number of words in all ham messages.\n",
    "\n",
    "The probability of a word given ham or spam is called a parameter because this probability does not change given any new message. The probability depends solely on the training set. So long as the training set does not change, our parameters do not change (hence, the term, parameter). \n",
    "\n",
    "In my calculation of the parameters, there's an alpha, $\\alpha$, component in both the numerator and denominator, and in the denominator, there's also a term that represents the number of words in the vocabulary, $N_{vocabulary}$. This process is called 'additive smoothing'. This method is employed because if there is a word in a new message that isn't in the vocabulary, instead of attaching a probability of 0 and nullifying the product of the various probabilties in the SMS message, we add 1 to the numerator and add the product of alpha and the length of the vocabulary to the denominator, and thus, keeping the product of the probabilities intact. Additive smoothing is performed on all words in a new SMS message. \n",
    "\n",
    "Since there are 8,030 unique words in the training set, 16,060 parameters will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the parameters\n",
    "\n",
    "parameters_spam = {unique_word: 0 for unique_word in vocab}\n",
    "parameters_ham = {unique_word: 0 for unique_word in vocab}\n",
    "\n",
    "for word in vocab:\n",
    "    p_word_given_spam = (spam_sms[word].sum() + alpha) / (n_spam + alpha * n_vocab)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    p_word_given_ham = (ham_sms[word].sum() + alpha) / (n_ham + alpha * n_vocab)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've created my variables, I can construct the spam filter. The following spam filter can take in messages (either directly written messages or messages in a dataframe) and <b>prints</b> out whether the message(s) is/are ham, spam, or needs human classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a spam filter that prints a classification of ham/spam/human assistance as the output\n",
    "\n",
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "   \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities. Requires human classification!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 3.374289191685471e-29\n",
      "P(Ham|message): 7.157887182915353e-32\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This following is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.9223605311263926e-24\n",
      "P(Ham|message): 1.126173821759989e-19\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Thanks, Dan. I'll see you tomorrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following spam filter can take in messages (either directly written messages or messages in a dataframe) and <b>returns</b> whether the message(s) is/are ham, spam, or needs human classification. I apply this spam filter on the test set and store the predicted values in a newly created column called <b>'Predicted'</b>. After running the algorithm on the test set, I calculate the accuracy of the spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a spam filter that, instead, returns ham/spam/human assistance as the output\n",
    "\n",
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ALSO TELL HIM I SAID HAPPY BIRTHDAY</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aiyo a bit pai seh ü noe... Scared he dun rem ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes..he is really great..bhaji told kallis bes...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>R u still working now?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanks da thangam, i feel very very happy dear...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS Predicted\n",
       "0   ham                ALSO TELL HIM I SAID HAPPY BIRTHDAY       ham\n",
       "1   ham  Aiyo a bit pai seh ü noe... Scared he dun rem ...       ham\n",
       "2   ham  Yes..he is really great..bhaji told kallis bes...       ham\n",
       "3   ham                             R u still working now?       ham\n",
       "4   ham  Thanks da thangam, i feel very very happy dear...       ham"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column in the test set that stores the predicted labels\n",
    "\n",
    "test_set['Predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 826\n",
      "Incorrect: 10\n",
      "Accuracy: 98.8 %\n"
     ]
    }
   ],
   "source": [
    "#Determine the accuracy of spam filter\n",
    "\n",
    "correct = 0\n",
    "total = len(test_set)\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['Predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', round((correct/total)*100, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "6     ham                             Nokia phone is lovly..   \n",
       "15    ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "24    ham                   No calls..messages..missed calls   \n",
       "41    ham  We have sent JD for Customer Service cum Accou...   \n",
       "226  spam  Oh my god! I've found your number again! I'm s...   \n",
       "268  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "463  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "598  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "607  spam                                      2/2 146tf150p   \n",
       "675  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                      Predicted  \n",
       "6                          spam  \n",
       "15   needs human classification  \n",
       "24                         spam  \n",
       "41                         spam  \n",
       "226                         ham  \n",
       "268                         ham  \n",
       "463                         ham  \n",
       "598                         ham  \n",
       "607                         ham  \n",
       "675                         ham  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the rows where the actual label does not match the predicted label\n",
    "\n",
    "test_set.loc[~(test_set['Label'] == test_set['Predicted'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Displayed directly above are the 10 messages for which labels were incorrectly predicted. Based on observation, it seems most of the spam messages can pass off as ham and vice versa, and thus, our spam filter did not classify these messages correctly.\n",
    "\n",
    "Having said that, the spam filter achieved an accuracy of 98.8%, which is excellent by any standard. The accuracy of the filter would climb higher if I trained the algorithm on more SMS messages from the original dataset. By training the algorithm with more data points, the probabilities that make up the Naive Bayes would more effectively account for ham and spam messages.\n",
    "\n",
    "In this project, I have employed the multinomiral Naive Bayes algorithm to create a spam filter. This classification technique can be used for other purposes as well such as predicting political alignment using Twitter data, the general direction of the stock market using data from daily news headlines, and etcetera.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
